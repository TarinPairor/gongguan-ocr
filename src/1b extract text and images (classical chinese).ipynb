{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract text and images (Classical Chinese)\n",
    "\n",
    "This file identifies the text lines manually labelled in Transkribus. It saves individual lines as text and images to different files, which can then be used to create a HF dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image, ImageDraw\n",
    "import pandas as pd\n",
    "import glob\n",
    "import itertools\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define dirs\n",
    "output_folder = \"../data/Chinese\"\n",
    "input_folder = f\"{output_folder}/7030191/Gongguan_sample\"\n",
    "text_output_folder = f\"{output_folder}/texts\"\n",
    "image_output_folder = f\"{output_folder}/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_chinese_text(text):\n",
    "    \"\"\"\n",
    "    Normalize text to standard Chinese Unicode form.\n",
    "    Converts variant Unicode characters (e.g., Kangxi Radicals) into normal forms.\n",
    "    \"\"\"\n",
    "    return unicodedata.normalize(\"NFKC\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_vertical_text(text_lines):\n",
    "    \"\"\"\n",
    "    Reorder Chinese text from row-major to column-major for vertical text.\n",
    "    \"\"\"\n",
    "    # Determine max length (widest line)\n",
    "    max_length = max(len(line) for line in text_lines)\n",
    "\n",
    "    # Pad all lines to the same length to ensure proper alignment\n",
    "    padded_lines = [line.ljust(max_length, \" \") for line in text_lines]\n",
    "\n",
    "    # Transpose: Convert rows to columns (read column-by-column, top-to-bottom)\n",
    "    vertical_text = [\"\".join(column) for column in itertools.zip_longest(*padded_lines, fillvalue=\" \")]\n",
    "\n",
    "    return \"\".join(vertical_text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse XML\n",
    "def parse_xml(file_path):\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "    namespace = {'ns': 'http://schema.primaresearch.org/PAGE/gts/pagecontent/2013-07-15'}\n",
    "\n",
    "    regions = []\n",
    "\n",
    "    # Iterate over TextRegion elements\n",
    "    for text_region in root.findall(\".//ns:TextRegion\", namespace):\n",
    "        region_id = text_region.get(\"id\")\n",
    "        coords_elem = text_region.find(\"ns:Coords\", namespace)\n",
    "\n",
    "        if coords_elem is None:\n",
    "            continue\n",
    "\n",
    "        # Extract individual TextLines (each one is a vertical string)\n",
    "        text_lines = [\n",
    "            line.find(\".//ns:Unicode\", namespace).text\n",
    "            for line in text_region.findall(\".//ns:TextLine\", namespace)\n",
    "            if line.find(\".//ns:Unicode\", namespace) is not None\n",
    "        ]\n",
    "\n",
    "        if not text_lines:\n",
    "            continue  # Skip empty regions\n",
    "\n",
    "        # Normalize all extracted text\n",
    "        normalized_lines = [normalize_chinese_text(line) for line in text_lines]\n",
    "\n",
    "        # Convert text_lines into vertical text format\n",
    "        vertical_text = reorder_vertical_text(normalized_lines)\n",
    "\n",
    "        # Extract coordinates\n",
    "        coords_str = coords_elem.get(\"points\")\n",
    "        regions.append((region_id, coords_str, vertical_text))\n",
    "\n",
    "    return regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw each text line with buffer and save as image\n",
    "def create_images_from_regions(page_name, image_path, regions, buffer_above=10, buffer_below=10, buffer_left=10, buffer_right=10):\n",
    "    data = []\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    for idx, (region_id, coords_str, region_text) in enumerate(regions):\n",
    "        # Parse the coordinates and find the bounding box\n",
    "        points = [tuple(map(int, point.split(','))) for point in coords_str.split()]\n",
    "        \n",
    "        x_coords = [p[0] for p in points]\n",
    "        y_coords = [p[1] for p in points]\n",
    "\n",
    "        min_x, max_x = min(x_coords) - buffer_left, max(x_coords) + buffer_right\n",
    "        min_y, max_y = min(y_coords) - buffer_above, max(y_coords) + buffer_below\n",
    "\n",
    "        # Crop the image to the bounding box\n",
    "        cropped_image = image.crop((min_x, min_y, max_x, max_y))\n",
    "\n",
    "        # Append the identifier and text to the data list\n",
    "        data.append([region_text, f'{page_name}_{region_id}'])\n",
    "\n",
    "        # Save text data to a CSV file\n",
    "        df = pd.DataFrame(data, columns=['text', 'identifier'])\n",
    "        df.to_csv(f'{text_output_folder}/{page_name}.csv', index=False)\n",
    "\n",
    "        # Save the cropped image\n",
    "        cropped_image.save(f'{image_output_folder}/{page_name}_{region_id}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xml_file_path in glob.glob(f\"{input_folder}/page/*.xml\"):\n",
    "    page_name = xml_file_path.split(\"/\")[-1].replace(\".xml\", \"\")\n",
    "    image_file_path = f\"{input_folder}/{page_name}.jpg\" \n",
    "\n",
    "    # Parse XML and extract text regions\n",
    "    regions = parse_xml(xml_file_path)\n",
    "\n",
    "    # Create images from the text regions\n",
    "    create_images_from_regions(page_name, image_file_path, regions, buffer_above=0, buffer_below=0, buffer_left=0, buffer_right=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
